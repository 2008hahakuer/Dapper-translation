Dapper，大规模集群的跟踪系统
作者：Benjamin H. Sigelman, Luiz Andr´e Barroso, Mike Burrows, Pat Stephenson,
Manoj Plakal, Donald Beaver, Saul Jaspan, Chandan Shanbhag

* 概述：
当代互联网的服务通常是搭建在大规模分布式集群上。互联网应用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言来实现、有可能布在了几千个节点，横跨很多台物理机上。因此，用来帮助理解系统行为、用于分析性能问题的工具在这样一个环境下就显得很必要了。
在这里我们要介绍一下Dapper的设计理念，Dapper是Google生产环境下的分布式跟踪系统。我们会介绍我们如何设计一个低损耗、对应用透明的、满足遍布在大规模集群需求的跟踪系统。Dapper参考了一些其他分布式系统的理念包括Magpie和X-Trace，但是一些关键性的设计点致使Dapper能成功应用在我们的生产环境中，比如使用采样率，把代码植入限制在非常小范围的Lib包的引入。
发表这篇论文最主要的目的汇报一下我们的构建和部署的经验以及两年来的使用经验，自从Dapper一流的监控功能对开发者和运维团队的提供的帮助。Dapper从一个独立的跟踪组件开始，但最终进化成一个包含了促生出多种多样的工具（其中的一部分甚至已经不是由Dapper团队开发的了）的监控平台。我们描述了一些分析工具是使用Dapper搭建的，分享出这些工具在google内部的分析数据，以及使用用例和迄今为止的一些讨论内容。

* 介绍
我们开发Dapper是为了给Google的开发者们提供更多的关于复杂分布式系统行为的信息。这样的系统有一个特殊的作用，因为大规模的低端服务器为互联网的各种服务提供了一个特殊的又经济划算的平台。在这个生产环境中理解分布式系统的行为需要观察这些横跨了不同的应用、不同的节点之间的彼此关联的动作。
下面举一个跟搜索相关的例子来阐述哪些挑战是Dapper需要处理的。一个前段服务可能对上百台查询节点发起了一个Web查询的请求，每一个查询都有自己的Index。这个查询可能会被发送到很多其他的子系统，这些子系统分别用来处理广告、进行拼写检查或是查找一些像图片、视频或新闻这样的特殊结果。最终的结果会从这些服务的结果中进行筛选，最后汇总到页面上。我们把这中搜索模型称为“全局搜索”（universal search）。总的来说，这一次全局搜索有可能调用上千个节点和多种多样的服务。而且，真正做搜索的这个用户对查询耗时是很敏感的，而查询耗时可能由于任何一个子系统的低效导致。如果一个工程师想查找这个低效的潜在原因，他可能只知道这是个问题，但是不知道这个问题是哪个服务调用造成的，或者为什么这个调用会表现的不尽如人意。首先这个工程师可能不能准确的定位到这次全局搜索是调用了哪个服务，因为新的服务甚至服务上的某个组成部分都有可能在任何一周被上线或修改过，而且这个服务有可能是直接对外的那部分也有可能是一些例如针对性能或安全认证方面的服务。第二，你不能苛求这个工程师对所有参与这次全局搜索的服务都了如指掌，这每一个服务都有可能是不同的团队开发并且维护的。第三，这些暴露出来的服务或节点有可能同时还被其他客户端使用着，所以一个这个全局搜索的性能问题有可能是其他应用造成的。举个例子，一个后台服务可能要应付各种各样的请求类型，或是一个使用效率很高的数据库库(Bigtable)可能正被很多很多应用使用着。
上面这个案例归结为对于Dapper的两个基础需求：无所不在的部署，以及持续监控。无所不在很是重要，因为在使用跟踪系统的过程中即便是一个很小的部分违背监控到，那么整个跟踪系统的可用性都会受到冲击。另外，监控应该是7x24的，因为通常是一些罕见或和非常见行为出现的状况，这些状况恰恰是不可重现的。那么，从这两个需求可以直接推出三个具体的设计目标：
1.低成本：跟踪系统应该有着对在线服务可以忽略不计的性能影响。在一些高度优化的服务，即使是很小的监测间接成本是很容易看到，并有可能迫使部署团队将跟踪系统关闭。
2.应用程序级别的透明度：程序员不应该需要知道跟踪系统的。一个为了能发挥作用需要依赖应用级别开发者的主动合作的跟踪系统是非常脆弱的，往往因内嵌的跟踪系统组件的错误或遗漏导致应用问题，才无法满足对跟踪系统无所不在的要求。这在一个快节奏的发展是特别重要，尤其像我们这样的环境。
3.可度量性：它需要处理Google的至少在未来几年的服务和集群的规模。
额外的设计目标是为跟踪数据产生之后可以迅速的利用到数据分析中，理想情况是一分钟之内。尽管跟踪分析系统一小时前的旧数据还是相当有价值的，提供新鲜的信息可以更快地反应生产异常。
真正的应用程序级别的透明度，这可能是我们最挑战性的设计目标，是通过限制核心代码至无所不在的线程的小语库（a small corpus of ubiquitous threading这让人怎么翻译）、控制流和RPC库代码。系统的可扩展性和性能降低开销得益于利用自适应
采样，这将在第4.4节中描述的。展示结果的系统也包含一些收集跟踪的数据的代码、用来图形化的工具以及用来分析大规模跟踪数据的库和API。虽然Dapper自身有时是足够让开发人员查明表现异常的来源，但是它的目的不是要取代所有其他的工具。我们已经发现，Dapper的全系统的数据往往侧重性能方面的调查，以便其他工具可以适用在本地。

1. 贡献的总结
具有分布式系统的跟踪工具的设计空间参照了一些以前的优秀文章，其中的Pinpoint、Magpie和X-Trace和Dapper最为相近。这些系统往往在其发展的早起在研究文献中被描述过，才会有机会
清楚地评估这个重要的设计选择。由于Dapper已经在大规模生产和经营
多年，我们觉得这将是最合适的时机把这篇论文重点放在Dapper的部署告诉了我们什么，我们的设计设计是如何实践的，以及以什么样的方式它才会是最有用的。Dapper，作为为开发性能分析
工具以及Dapper自身作为监测工具提供的平台，它的价值是我们可以在回顾评估中找出一些意想不到的结果。
虽然Dapper在许多高层次的设计思想上与Pinpoint和Magpie有异曲同工之妙，但我们的实现包含了许多在这个领域中的新的贡献。例如，我们对于低消耗来说采样率是必要的，特别是在高度优化的而且往往是对延迟相当敏感的Web服务中。或许更令人惊讶的是，我们发现即便是1/1000的采样率也可以提供许多常见用途的总以用来展现信息的跟踪数据。
我们的系统的另一个重要的特征是我们能实现的应用程序级的透明程度。我们的组件在软件堆中被限制到在足够低的水平，即使是规模大如Google网页搜索的分布式系统也可以进行跟踪而无需额外的注释。虽然由于我们的部署系统有幸是一定程度的同质化的，导致更容易做到这点（透明性），但是我们证明了这是实现这种程度的透明度的充分条件（汗...）。

2.Dapper的分布式跟踪
分布式的跟踪组件需要记录在一次特定的请求后系统中完成的所有的工作记录下的信息。举个例子，图1展现的是一个和5个服务器相关的一个服务，包括：前段（A），两个中间层（B和C），以及两个后端（D和E）。当一个用户作为这个用例的发起人发起一个请求时，首先到达前段，然后发送两个RPC到服务器B和C。B会发上做出反应，但是C需要和后端的D和E交互之后再返还给A，这反过来又响应最初的请求。一个简单而有用的分布式跟踪的需求就是为每一个消息在每个服务器上发送和接收收集消息的标识符和时间戳。
两个类别的解决方案已经被提出来用来汇总此信息，以便可以将所有记录条目与一个给定的发起者（例如，图1中的RequestX），黑盒和基于注解的监控方案。黑盒方案[1，15，2]（这里指本论文的引用，会在文章结尾处列出）假定这里没有额外的信息除了上文所述的这些内容（id,timestamp），使用统计回归技术来推断两者之间的关系。基于注解的方案[3，12，9，16]依赖于应用程序或中间件明确地标记一个全局标识符，每一条记录连接这些消息记录的请求。虽然黑盒计划比注解的方法更轻便，他们需要更多的数据，以获得足够的精度，因为他们依赖于统计推论。基于标注的方案最主要的缺点是，很明显，需要组件的程序开发。在我们的环境中，因为所有的应用程序使用相同的线程模型，控制流和RPC系统中，我们发现，可以限制组件至一个很小的通用库中，并实现了监测系统的应用对开发人员是有效和透明的。
我们倾向于认为，Dapper的跟踪架构是嵌套RPC的树形结构。然而，我们的核心数据模型不限制在
我们的特定的RPC框架，我们还跟踪其他行为如在Gmail的SMTP会话，外界的HTTP请求，和外部对SQL服务器的查询。从形式上看，我们的Dapper跟踪模型使用的树形结构，跨度以及标注。

2.1跟踪树和段
在Dapper跟踪树结构中，树节点是整个架构的基本单元，整个架构又是对段的引用。它的边缘表示的段和它的父段跨度的因果关系。跨度在整个树形结构中是相对独立的，虽然一个跨度也是一个简单的日志记录了开始和结束时间，任何RPC相关的时间数据、零个或多个特定应用程序的标注的相关内容会在在2.3节中讨论。
我们在图2中说明了段在一个大的跟踪操作中是什么样的。Dapper记录了人类可读的段的名字，以及每个段的ID和父段ID，以重建在一次追踪过程中不同段之间的关系。如果一个段没有父ID被称为根段。所有段都挂在一个特定的跟踪上，也共用一个跟踪id（在图中未示出）。所有这些ID概率唯一的64位整数。在一个典型的Dapper的跟踪中，我们希望为每一个RPC对应到一个单一的段上，而且每一个额外的组件层都对应一个跟踪树型结构的层级。
图3给出了一个更详细的典型的Dapper跟踪段的日志事件的视图。在图2中这种特殊的段表述了两个“Helper.Call”的RPC。段的开始和结束时间，以及任何RPC的时间信息都被Dapper的RPC库组件记录下来。如果应用程序所有者选择在跟踪中增加他们自己的注释（如图中“foo”的注释），这些信息也会和其他段信息一样记录下来。
记住，任何一个段可以包含来自多个主机的信息，这些也要记录下来。事实上，每一个RPC段包含
从客户端和服务器过程的注释，使得链接连个主机的段会成为最常见的形式（这里的意思是，比如有一次调用，我们称为段A，是从C1节点对C2节点的调用，那么这个A就连接C1和C2，它就能获取到C1和C2两端的信息）。由于客户端和服务器上的时间戳来自不同的主机，我们必须考虑到时间偏差。在我们的分析工具，我们利用了这个事实：RPC客户端发送一个请求之后，服务器端才能接收到，对于响应也是一样的（服务器先响应，然后客户端才能接收到这个响应）。这样一来，服务器端的RPC就有一个时间戳的一个上限和下限。

2.2组件的要点
Dapper可以以对应用开发者近乎零干涉的成本对分布式控制路径进行跟踪，完全依赖于基于少量通用库的组件。如下：
@当一个线程在处理跟踪控制路径的过程中，Dapper把这次跟踪的上下文的在ThreadLocal中进行存储。追踪上下文是一个小而且容易复制的容器承载了段的属性比如跟踪ID和其他段ID。
@当计算过程被推迟或是异步的，大多数Google开发者使用一个通用控制流库来回调和放入线程池或其他executor。Dapper确保所有这样的回调可以存储这次跟踪的上下文，而当回调函数被触发时，这次跟踪的上下文会与适当的线程关联上。在这种方式下，用来在异步后重建这次跟踪的Dapper的id可以透明的跟踪异步控制路径（In this way, the Dapper
ids used for trace reconstruction are able to follow
asynchronous control paths transparently.这的意思可能是用了一个唯一标示来辅助构建异步调用的路径）。
@几乎所有的Google的进程间通信是建立在一个用C++和Java开发的RPC框架上。我们使用该框架定义RPC中所有的段。段的ID和跟踪的ID会从客户端发送到服务器。像那样的基于RPC的系统被广泛使用在谷歌中，这是一个重要的监测点。当他们的发展成熟找到了自己的用户群之后，我们计划构建非RPC通信框架。

Dapper的跟踪数据是独立于语言的，很多在生产环境中的跟踪结合了用C++和Java写的进程的数据。在3.2节中，我们讨论应用程序的透明度时我们会把这些理论的落地进行讨论。

2.3标注
上述要点足够推导出复杂的分布式系统跟踪详细，使得Dapper的核心功能在不改动Google应用的情况下可用。然而，Dapper还允许应用程序开发人员在Dapper跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。我们允许用户通过一个简单的API定义时间戳的标注，核心的示例代码入图4所示。这些标注可以添加任意内容。为了保护Dapper的用户意外的过分热衷于日志的记录，独立的跟踪段有一个可配置的总标注量的上限。应用程序级的标注是不能够用应用程序的行为来取代结构段或RPC的信息。
除了简单的文本标注，Dapper也支持的key-value的Map标注，让开发人员更多的跟踪能力，如保持计数器，二进制消息记录和在一个进程内的跟踪请求上传输任意用户定义的数据。键值对的标注方式用来在分布式追踪的上下文中定义特定于应用程序的等价类型。

2.4采样率
低开销的是Dapper的一个关键设计目标，因为如果这个工具价值未被证实但又对性能有所影响的话，服务运营人员不愿意部署它也是可以理解的。况且，我们想让开发人员使用标注的API，而不用担心额外的开销。我们还发现，某些类别的Web服务是对组件的性能损耗十分敏感的。因此，除了使Daper的的收集工作对基本组件的性能消耗尽可能地小，我们有进一步控制消耗的办法，那就是只记录很多跟踪中的一小部分的。我们将在4.4节中讨论这个跟踪的更多细节。

2.5跟踪的收集
Dapper的跟踪记录和收集管道是一个分三个阶段的过程中（参见图5）。首先，段数据
写入（1）本地日志文件。然后Dapper的守护进程和收集组件把这些数据从生产环境的主机中拉出来（2），最终写到（3）独特的区域型Dapper Bigtable仓库中（比如咱们的HBASE）。一次跟踪被设计成Bigtable中的一行，每一列相当于一个段。Bigtable的支持稀疏表格布局正适合这种情况，在这里，因为每一次跟踪可以有任意的段。跟踪数据收集的平均延迟--也就是说，从应用中的二进制数据传输到中央仓库（Bigtable）所花费的时间，不多于15秒。98的百分比延迟是随着时间的推移双峰分布的（bimodal），约75％的时间，98%的收集延迟是少于两分钟的，但其余约25％的时间可以长达数小时（这句话挺绕的，最好看看原文，我也翻译不出来）。
Dapper还提供了一个API来简化访问我们仓库中的跟踪数据。Google的开发人员用这个API，以构建通用和特定应用程序的分析工具。第5.1节包含更多关于它的使用的的信息

2.5.1带外（out-of-band）跟踪收集
Dapper系统带需求树自身进行跟踪记录和收集带外数据。（The Dapper system as described performs trace logging
and collection out-of-band with the request tree itself）
这样做是为两个不相关的原因。首先，带内收集方案--这里跟踪数据会以RPC响应头的形式被返回--可以影响应用程序网络动态。在Google里的许多规模较大的系统中，成千上万的段并不少见。然而，RPC回应大小--甚至是接近大型分布式的跟踪的根节点的这种情况下-- 仍然是比较小的：通常小于10K。在这种情况下，带内Dapper的跟踪数据会让应用程序数据和倾向于使用后续分析结果的数据量相形见绌。除此之外，带内收集方案假定所有的RPC是完美
嵌套的。我们发现，在所有的后端的系统返回的最终结果之前，有许多中间件会把结果返回给他们的调用者。带内收集系统是无法解释这种非嵌套的分布式执行模式的（这段的翻译还是好好看看原文吧，太晦涩了，不过大概意思应该是这样,带内（in-band）可能指的是系统内自己的收集，（out-of-band）可能指的是作为独立于组件的数据收集方式）。

2.6安全和隐私考虑
记录一定量的RPC有效负载信息将丰富Dapper的跟踪能力，因为分析工具能够在有效载荷数据中找到相关的模式，这写模式可以解释被监控系统的表现异常。然而，有几种情况是有效载荷数据可能包含的一些不应该透露给未经授权用户的内部信息，包括工程师在做性能调试工作的情况。
由于安全和隐私问题是不可忽略的，dapper中的虽然存储RPC方法的名称，但在这个时候不记录任何有效载荷数据。相反，应用程序级别的标注提供了一个方便的可选机制：应用程序开发人员可以在段中选择关联那些为以后分析提供价值的数据。
Dapper还提供了一些安全上的好处，是它的设计者事先没有预料到的。通过跟踪公开的安全协议参数，Dapper可以通过相应级别的认证或加密，来监视应用程序是否满足安全策略。例如。Dapper还可以提供信息，以基于策略的的隔离系统按预期执行，例如支撑敏感数据的应用程序不与未经授权的系统组件进行了交互。这样的测算提供了比源码审核更强大的保障。

3.Dapper部署状况
Dapper作为我们生产环境下的跟踪系统已经超过两年。在本节中，我们会针对系统状态展现出一些东西，把重点放在Dapper如何满足了我们的目标——无处不在的部署和应用程序级别的透明度。

3.1Dapper运行库
也许Dapper代码中中最关键的部分，就是关于基础RPC、线程控制和流程控制的库，其中包括段的创建，采样率的设置，以及把日志写入本地磁盘。除了做到轻量级，这段代码更需要稳定和健壮，因为它与海量的应用对接，维修和bug修复变得困难。核心代码是由未超过1000行的C++和不超过800行Java代码实现的。实现键值对的标注还添加了额外的500行代码。

3.2生产环境下的涵盖面
Dapper的渗透可以总结为两个方面：一方面是可以创建Dapper跟踪的生产进程（比如那些连接到Dapper运行库部分），和生产环境下的节点在运行Dapper跟踪收集守护进程。Dapper的守护进程是我们基本的服务器映像（basic machine image），使它存在于Google几乎所有的服务器上。这很难确定精确的Dapper-ready进程部分，因为过程即便不产生跟踪信息Dapper也是无从知晓的。尽管如此，考虑到无处不在Dapper组件的植入库，我们估计几乎每一个Google的生产进程都是
支持跟踪的。
在某些情况下Dapper的是不能正确的跟踪控制路径的。这些通常源于使用非标准的控制流​​，或是Dapper的错误的把段与段之间的联系归到不相关的事件上。Dapper提供了一个简单的库来帮助开发者手动控制跟踪传播作为一种变通方法。目前有40个C++应用程序和33个Java应用程序需要一些手动控制的追踪传播，不过这只是上前的跟踪中的一小部分。也有一个很小一部分程序使用的非组件性质的通信库库（比如原生的TCP Socket或SOAP RPC），因此不能直接支持Dapper的跟踪。但是这些应用可以单独接入到Dapper中，如果需要的话。
考虑到生产环境的安全，Dapper的跟踪也可以关闭。事实上，早起它默认就是关闭的，直到我们对Dapper的稳定性和低开销有了足够的信心之后才把它开启。Dapper的团队偶尔会执行审查寻找跟踪配置的变化，来看看那些服务关闭了Dapper的跟踪。但这种情况不多见，而且通常是源于对监控对性能消耗的担忧。经过了对实际性能消耗的进一步调查和测量，所有这些关闭Dapper的改变至今都已经恢复，不过这些已经不重要了。

3.3跟踪标注的使用
程序员倾向于使用特定于应用程序的标注无论是作为一种分布式调试日志文件或通过一些应用程序特定的功能进行分类跟踪。例如，所有的Bigtable的请求的都标注了被访问的表的名称。目前，70％的Dapper段和90％的所有Dapper跟踪至少有一个应用程序指定的标注。
41个Java应用和68个C++应用中都添加自定义的标注为了更好地理解应用程序中的段在他们的服务中的行为。值得注意的是，迄今为止我们的Java开发者比C++开发者更多的在每一个跟踪段上采用标注的API。这可能是因为我们的Java工作负载往往是更接近最终用户;这些类型的应用程序经常处理更广泛的请求组合，因此具有比较复杂的控制路径。


